#!/bin/bash

llmr() {
    # Default values
    local model="openai/o4-mini"
    # local model="openai/gpt-4.1"
    local mode="default"
    local files=()
    local named_args=()
    local base_folder="$HOME/utils/llmr"
    local use_reasoning=false  # New flag for reasoning mode

    # Parse positional arguments
    if [[ $# -ge 1 ]]; then
        model="$1"
        shift
    fi

    if [[ $# -ge 1 ]]; then
        mode="$1"
        shift
    fi

    # Parse remaining arguments as files
    while [[ $# -gt 0 ]]; do
        if [[ "$1" == "--"* ]]; then
            # Handle named arguments (--arg value format)
            named_args+=("$1" "$2")
            shift 2
        else
            # Handle file paths
            files+=("$1")
            shift
        fi
    done

    # Map mode numbers to names
    declare -A mode_map
    mode_map["1"]="default"
    mode_map["2"]="coding"
    mode_map["3"]="coding-prompt-generator"
    mode_map["4"]="code-analyst"

    # Map model letters to names
    declare -A model_map
    model_map["g"]="gemini-2.5-pro-preview-03-25"
    # model_map["g"]="gemini-2.5-pro-exp-03-25"
    model_map["o"]="openai/o4-mini"
    model_map["O"]="openai/o3"
    # model_map["o"]="openai/gpt-4.1"
    model_map["c"]="claude-3.7-sonnet"

    # Interactive mode selection
    local confirmed=false
    while [[ "$confirmed" != true ]]; do
        echo "Current settings:"
        echo "  Model: $model"
        echo "  Mode: $mode"
        echo "  Reasoning mode: $(if $use_reasoning; then echo "ON"; else echo "OFF"; fi)"
        echo "  Files: ${files[*]}"
        echo "  Named args: ${named_args[*]}"
        echo ""
        echo "Options:"
        echo "  Press Enter to confirm and run"
        echo "  Type a number to change mode (1=default, 2=coding, 3=coding-prompt-generator, 4=code-analyst)"
        echo "  Type a letter to change model (g=gemini, o=openai, O=openai/o3, c=claude)"
        echo "  Type 'r' to toggle reasoning mode (for Claude model)"
        echo "  Type 'x' to add a named argument"
        echo "  Type 'm' to specify a custom model name"

        read -r choice

        if [[ -z "$choice" ]]; then
            confirmed=true
        elif [[ "$choice" =~ ^[1-4]$ ]]; then
            mode="${mode_map[$choice]}"
        elif [[ "$choice" =~ ^[goc]$ ]]; then
            model="${model_map[$choice]}"
        elif [[ "$choice" == "r" ]]; then
            use_reasoning=$(! $use_reasoning; echo $?)
            use_reasoning=$([[ $use_reasoning -eq 0 ]])
        elif [[ "$choice" == "x" ]]; then
            echo "Enter argument name (with --): "
            read -r arg_name
            echo "Enter argument value: "
            read -r arg_value
            named_args+=("$arg_name" "$arg_value")
        elif [[ "$choice" == "m" ]]; then
            echo "Enter custom model name: "
            read -r model
        else
            echo "Invalid choice. Please try again."
        fi
    done

    # Create necessary directories
    local mode_folder="$base_folder/$mode"
    local log_folder="$mode_folder/log"
    mkdir -p "$log_folder"

    # Ensure required files exist
    touch "$mode_folder/task.md"
    touch "$mode_folder/instructions.md"
    touch "$mode_folder/output.md"
    touch "$mode_folder/last-log.md"

    # Build the prompt
    local prompt=""

    # Add instructions
    if [[ -f "$mode_folder/instructions.md" ]]; then
        prompt+="<instructions>
$(cat "$mode_folder/instructions.md")
</instructions>

"
    fi

    # Add task
    if [[ -f "$mode_folder/task.md" ]]; then
        prompt+="<task>
$(cat "$mode_folder/task.md")
</task>

"
    fi

    # Add context from files if provided
    if [[ ${#files[@]} -gt 0 ]]; then
        local context
        context=$(files-to-prompt "${files[@]}")
        prompt+="<context>
$context
</context>

"
    fi

    # Current timestamp for log file
    local timestamp=$(date +"%Y-%m-%d_%H-%M-%S")
    local log_file="$log_folder/$timestamp.md"

    echo "Running llm with model: $model"
    echo "Mode: $mode"
    if $use_reasoning && [[ $model == *"claude"* ]]; then
        echo "Reasoning mode: ON"
    fi

    echo "--------------------------------------------"
    # Call llm with the assembled prompt
    local llm_response
    if $use_reasoning && [[ $model == *"claude"* ]]; then
        # Use reasoning mode for Claude
        llm_response=$(echo -e "$prompt" | llm -m "$model" "${named_args[@]}" -o thinking 1 -o thinking_budget 1025 --no-stream)
    else
        # Default mode
        llm_response=$(echo -e "$prompt" | llm -m "$model" "${named_args[@]}" --no-stream)
    fi

    # Get logs and extract information
    local logs
    logs=$(llm logs -n 1 --json)
    local id=$(echo "$logs" | jq -r '.[0].id')
    local model_used=$(echo "$logs" | jq -r '.[0].response_json.model')
    local response_id=$(echo "$logs" | jq -r '.[0].response_json.id')

    # Handle token information and pricing
    local input_tokens=$(echo "$logs" | jq -r '.[0].input_tokens')
    local output_tokens=$(echo "$logs" | jq -r '.[0].output_tokens')
    local total_tokens=$(echo "$logs" | jq -r '.[0].response_json.usage.total_tokens')
    local object_type=$(echo "$logs" | jq -r '.[0].response_json.object')

    # Calculate pricing based on model
    local model_info=""

    if [[ $model_used == *"gemini"* ]]; then
        local input_price=$(awk "BEGIN {printf \"%.6f\", $input_tokens * 1.25 / 1000000}")
        local output_price=$(awk "BEGIN {printf \"%.6f\", $output_tokens * 10.00 / 1000000}")
        model_info="**gemini usage**:
- input_tokens: $input_tokens (price: \$${input_price})
- output_tokens: $output_tokens (price: \$${output_price})"
    elif [[ $model_used == *"gpt"* ]]; then
        local input_price=$(awk "BEGIN {printf \"%.6f\", $input_tokens * 2.00 / 1000000}")
        local output_price=$(awk "BEGIN {printf \"%.6f\", $output_tokens * 8.00 / 1000000}")
        model_info="**Object type**: $object_type
**openai usage**:
- input_tokens: $input_tokens (price: \$${input_price})
- output_tokens: $output_tokens (price: \$${output_price})
- total_tokens: $total_tokens"
    elif [[ $model_used == *"claude"* ]]; then
        local input_price=$(awk "BEGIN {printf \"%.6f\", $input_tokens * 3.00 / 1000000}")
        local output_price=$(awk "BEGIN {printf \"%.6f\", $output_tokens * 15.00 / 1000000}")
        model_info="**claude usage**:
- input_tokens: $input_tokens (price: \$${input_price})
- output_tokens: $output_tokens (price: \$${output_price})"
    fi

    # Create log content
    local log_content="
# llm id: $id
**Model**: $model_used
**Response id**: $response_id
$model_info

# Input Text:
$prompt

# Output Text:
$llm_response
"

    # Save logs and output
    echo "$llm_response" > "$mode_folder/output.md"
    echo "$log_content" > "$mode_folder/last-log.md"
    echo "$log_content" > "$log_file"

    # Display the response and additional information
    echo "$llm_response"
    echo ""
    echo "----------------------------------------"
    echo "Model: $model_used"
    echo "Input tokens: $input_tokens"
    echo "Output tokens: $output_tokens"
    echo "Total tokens: $total_tokens"
    echo "Log saved to: $log_file"
}
llmr "$@"
